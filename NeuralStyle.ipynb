{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SananSuleymanov/Neural_Style_Transfer_video/blob/main/NeuralStyle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Steps to follow:**\n",
        "1. Load model\n",
        "2. Read style image and preprocess\n",
        "3. Read the frame of the video and preprocess it\n",
        "4. Apply Neural style transfer to the frame \n",
        "5. Reapeat 3 and 4 till the last frame and save it using OpenCV VideoWriter function"
      ],
      "metadata": {
        "id": "AboMbWOSllPQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN3chac0WFTW"
      },
      "source": [
        "#Required Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2bx7Ml25WE3S"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import PIL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5Ga0HNGS2SY"
      },
      "source": [
        "#Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MpC9coVGS6to"
      },
      "outputs": [],
      "source": [
        "hub_model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72ilBhK0QIa2"
      },
      "source": [
        "#Processing image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read image, convert to tensor, normalize and resize \n",
        "def image_read(image):\n",
        "  max_dim=512\n",
        "  image= tf.convert_to_tensor(image, dtype = tf.float32)\n",
        "  image= image/255.0\n",
        "  shape = tf.cast(tf.shape(image)[:-1], tf.float32)\n",
        "  long_dim = max(shape)\n",
        "  scale = max_dim/long_dim\n",
        "  new_shape = tf.cast(shape*scale, tf.int32)\n",
        "  new_image = tf.image.resize(image, new_shape)\n",
        "  new_image = new_image[tf.newaxis, :]\n",
        "  \n",
        "  return new_image"
      ],
      "metadata": {
        "id": "hOIlkH-HoWfs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LnLRvvG1m7X7"
      },
      "outputs": [],
      "source": [
        "#convert tensor to numpy array\n",
        "def tensor_toimage(tensor):\n",
        "  tensor =tensor*255\n",
        "  tensor = np.array(tensor, dtype=np.uint8)\n",
        "  if np.ndim(tensor)>3:\n",
        "    assert tensor.shape[0]==1\n",
        "    tensor=tensor[0]\n",
        "\n",
        "  return tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYcnyKVdSm-d"
      },
      "source": [
        "#Reading style image and content video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Lkz-mP-whiVH"
      },
      "outputs": [],
      "source": [
        "style_im = cv2.imread(\"/content/style.jpg\")\n",
        "style_im = cv2.cvtColor(style_im, cv2.COLOR_BGR2RGB)\n",
        "style_im = image_read(style_im)\n",
        "\n",
        "cap = cv2.VideoCapture(\"/content/content.mp4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transfer Video\n",
        "\n"
      ],
      "metadata": {
        "id": "b_lkPPjiovq6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "38KTlUdwlx0G"
      },
      "outputs": [],
      "source": [
        "#in order to get the size of width and shape of video, we used first frame of video\n",
        "ret, frame = cap.read()\n",
        "frame_width = image_read(frame)[0].shape[1]\n",
        "frame_height= image_read(frame)[0].shape[0]\n",
        "\n",
        "out = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'XVID'), 10, \n",
        "                      (frame_width,frame_height))\n",
        "\n",
        "while True:\n",
        "  ret, frame = cap.read()\n",
        "  if ret == True:\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    frame = image_read(frame)\n",
        "    stylized_frame = hub_model(tf.constant(frame), tf.constant(style_im))[0]\n",
        "    image = tensor_toimage(stylized_frame)\n",
        "    out.write(image)\n",
        "  else:\n",
        "    break\n",
        "\n",
        "cap.release()\n",
        "out.release()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGF5Lwy9G3LXd0qBBPqk+d",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}